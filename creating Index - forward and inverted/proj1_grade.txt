Final Grade: 105/100

"Part 1: 34/35 
19/20 points: Your tokenization algorithm is correct: you produce the correct stream of tokens from a given HTML document
5/5 points: The contents of docids.txt are correct
5/5 points: The contents of termids.txt are correct
5/5 points: The contents of doc_index.txt are correct
0/5 Extra credit points: Your program's memory usage is constant with respect to the number of documents, terms, and term positions indexed
The program must accept the corpus folder name as a command line argument

"Part 2: 41/35
15/15 points: You correctly construct the inverted index
6/10 points: Your inverted lists are correctly delta-encoded
5/5 points: The contents of term_index.txt are correct
5/5 points: The contents of term_info.txt are correct
0/5 Extra credit points: Your program's memory usage is constant with respect to the number of documents and term positions indexed
10/10 Extra credit points: Your program's memory usage is constant with respect to the number of terms indexed, and its runtime is linear with respect to the length of the input file
Comments: Wrong delta encoding of term Ids. 

"Part 3: 30/30
10/10 points: Looking up a document works correctly
10/10 points: Looking up a term works correctly
10/10 points: Looking up an inverted list works correctly
comments: your code didn't handle the situation where a doc or term can't be found in the corpus."
